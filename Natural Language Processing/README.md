
## Определение тональности текста
### Стек инструментов
Библиотеки nltk и spacy.
Предобработка текстов, лемматизация и векторизация.
Модели sklearn и BERT.
### Вводные данные
Интернет-магазин запускает новый сервис, в котором пользователи могут редактировать и дополнять описания товаров.  
Необходимо построить модель классификации комментариев на позитивные и негативные.  
В нашем распоряжении есть набор данных с разметкой о токсичности правок.  

### Цель
Обучить модель классифицировать комментарии на позитивные и негативные.

### Структура проекта  

1. Изучение данных и подготовка их для обучения:
    * Проведение лемматизации;
    * Очистка от лишних символов;
    * Векторизация комментариев с помощью метода tf_idf;
2. Обучение классических моделей прогнозирования;
3. Использование BERT;
4. Анализ результатов.

### Общий вывод

В данной работе мы обучили модель классифицировать комментарии на позитивные и негативные.
Наилучший результат по качеству и скорости работы был показан моделью логистической регрессии, обученной на векторизированных и сбалансированных данных - f1 = 0.76, Wall time: 6.6 s

Использование BERT дало следующие результаты:
На выборке из 200 комментариев BERT совместно с логистической регрессией показал результат f1 = 0.67 и время работы около 4х минут. Результат на выборке в 2000 комментариев был равен 0.72, время работы составило 35 минут.
Можно предположить, что на полной выборке результат будет примерно равен 0.8, но обучение займет в этом случае очень много времени.
