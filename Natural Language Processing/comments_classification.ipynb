{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online store is launching a new service in which users can edit and supplement product descriptions. The store needs a tool that will find toxic comments and send them for moderation.  \n",
    "  \n",
    "We need to build a model to classify comments into positive and negative ones.  \n",
    "We have a dataset with annotations on the toxicity of comments at our disposal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plan for the project:\n",
    "\n",
    "1. Studying the data;\n",
    "2. Preparing data for training models:\n",
    "     * Lemmatization;\n",
    "     * Cleaning of extra symbols;\n",
    "     * Vectorization of comments using the tf_idf method;\n",
    "3. Training classical prediction models;\n",
    "4. Using BERT;\n",
    "5. Analyzing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Studying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from tqdm import notebook\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and conduct the data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_comments.info())\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset:\n",
    "\n",
    "* text - user comments, object type;\n",
    "* toxic - toxicity of the comment.\n",
    "    - 0 - comment is positive.\n",
    "    - 1 - comment is negative.  \n",
    "    \n",
    "There are about 160,000 objects in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the ratio of positive and negative values of the toxic feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89.832112\n",
       "1    10.167888\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments['toxic'].value_counts()/df_comments['toxic'].shape*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection is unbalanced, the share of negative comments is about 10% of the entire sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for duplicates and missing values in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we conducted a preliminary study of the dataset data:\n",
    "\n",
    "* There are slightly less than 160,000 objects in the dataset;\n",
    "* Two features - user comments and a comment tonality classifier;\n",
    "* The data is unbalanced. Negative comments make up about 10% of the entire sample;\n",
    "* There are no duplicates and missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we conducted a preliminary study of the dataset data:\n",
    "\n",
    "- There are slightly less than 160,000 objects in the dataset;\n",
    "- Two features - user comments and a comment tonality classifier;\n",
    "- The data is unbalanced. Negative comments make up about 10% of the entire sample;\n",
    "- There are no duplicates and missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Lemmatization and cleaning of extra symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct lemmatization, we will use the Wordnet Lemmatizer with NLTK library.  \n",
    "  \n",
    "In the process of implementing the project, lemmatization was performed in two ways:\n",
    "\n",
    "1. Standard lemmatization;\n",
    "2. Lemmatization using POS tagging, when the part of speech is determined for each word.  \n",
    "    In this variant, more correct lemmatization was carried out, for example, the verbs \"are\" and \"is\" were turned into the verb \"be\".  \n",
    "\n",
    "However, following the training of models and analysis of results, we only kept the first option for the following reasons:\n",
    "\n",
    "- faster operation of the method - the first option took one minute, the second thirty-one minutes;\n",
    "- with a much faster operation of the first algorithm, the results were the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Creating a corpus with all existing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_comments['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first comment, record it and compare it with the lemmatized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform lemmatization using the Wordnet Lemmatizer with NLTK library without using POS-tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 598 ms, total: 1min 15s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(corpus)):\n",
    "    # delete all special characters\n",
    "    document = re.sub(r'\\W', ' ', str(corpus[sen]))\n",
    "    \n",
    "    # delete all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # remove single characters from the beginning of the string\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # replace several spaces with one\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # remove the prefix 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # convert uppercase letters to lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    lemmas.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what result we got after lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they weren vandalism just closure on some gas after voted at new york doll fac and please don remove the template from the talk page since m retired now 89 205 38 27'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is ready for processing. On Kaggle they recommend not deleting them, so we won't touch them.\n",
    "\n",
    "We'll convert our list of lemmas into Series and add it to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour m seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man m really not trying to edit war it jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more can make any real suggestion on improveme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              lemmas  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour m seemin...  \n",
       "2  hey man m really not trying to edit war it jus...  \n",
       "3  more can make any real suggestion on improveme...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_series = pd.Series(lemmas, name = 'lemmas')\n",
    "df_comments_new = pd.concat([df_comments, lemmas_series], axis = 1)\n",
    "df_comments_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, an attempt was made to lemmatize using the Wordnet Lemmatizer with NLTK library in two methods - standard and with POS-tagging.  \n",
    "\n",
    "The first method took 1 minute, the second one 31 minutes. Slight improvements in the quality of lemmatization by the second method did not add to the result of forecasting, so the first option was left.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Vectorization of data using the tf_idf method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform vectorization of data using the tf_idf method.  \n",
    "  \n",
    "For this, we'll isolate the target feature into a separate dataset and divide the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_features = df_comments_new.drop(['text','toxic'], axis=1)\n",
    "comments_target = df_comments_new['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rest, y_train, y_rest = train_test_split(\n",
    "    comments_features, comments_target, test_size=0.4, random_state=12345)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_rest, y_rest, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the size of the resulting tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95742, 1)\n",
      "(31914, 1)\n",
      "(31915, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a counter, specifying stop words in it, i.e. words without semantic load.  \n",
    "For this, we previously downloaded the stopwords package for the English language, which is located in the nltk.corpus module of the nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create corpora of comments from the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = X_train['lemmas'].values\n",
    "corpus_valid = X_valid['lemmas'].values\n",
    "corpus_test = X_test['lemmas'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the converter on the corpus_train sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.7, max_features=6000,\n",
       "                min_df=5, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfconverter = TfidfVectorizer(max_features=6000, min_df=5, max_df=0.7, stop_words=stopwords)\n",
    "tf_idfconverter.fit(corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert all samples into matrices and check their dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = tf_idfconverter.transform(corpus_train)\n",
    "X_valid_tf = tf_idfconverter.transform(corpus_valid)\n",
    "X_test_tf = tf_idfconverter.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95742, 6000)\n",
      "(31914, 6000)\n",
      "(31915, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf.shape)\n",
    "print(X_valid_tf.shape)\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the dataset was divided into training, validation and test samples in a ratio of 3/1/1 and user comments were vectorized using the tf_idf method.  \n",
    "  \n",
    "As a result, matrices were obtained with the number of features equal to 130,886."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Handling data imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed earlier, the number of negative comments is much less than positive ones.  \n",
    "This is good for our service, but bad for our prediction models.  \n",
    "So, using the upsampling method, we'll increase the number of negative comments.  \n",
    "\n",
    "We will perform the transformation in several stages:\n",
    "\n",
    "* Divide the training sample into positive and negative comments;\n",
    "* Copy negative comments several times.\n",
    "* In our case, we increase the sample of negative comments 8 times;\n",
    "* Based on the obtained data, we'll create a new training sample;\n",
    "* We'll shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, y_train_up = upsample(X_train, y_train, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры таблицы features_upsampled: (164013, 1)\n",
      "Размеры таблицы target_upsampled: (164013,)\n",
      "\n",
      "0    0.524282\n",
      "1    0.475718\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Table size features_upsampled:', features_upsampled.shape)\n",
    "print('Table size target_upsampled:',y_train_up.shape)\n",
    "print()\n",
    "print(y_train_up.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing upsampling, the classes became balanced, and the size of the tables increased.  \n",
    "\n",
    "We'll create a new corpus of training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_up = features_upsampled['lemmas'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the new sample into a matrix and check its dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_up = tf_idfconverter.transform(corpus_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164013, 6000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_up.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensionality matches the samples obtained earlier. Everything is great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the data preparation for forecasting, we successfully carried out:\n",
    "\n",
    "- Lemmatization using the Wordnet Lemmatizer with NLTK library;\n",
    "- We cleaned the data from unnecessary characters;\n",
    "- Vectorized using the tf_idf method;\n",
    "- Balanced the number of positive and negative comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll conduct the training of models and look at the results obtained on the validation sample.  \n",
    "\n",
    "For this, we'll create a function for training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_models(models, ft, tt, fv, tv):\n",
    "    model = models\n",
    "    model.fit(ft, tt)\n",
    "    predictions_valid = model.predict(fv)\n",
    "    print('f1 = {:.2f}'.format(f1_score(tv, predictions_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train several models, compare the results and working time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression with data balancing before performing upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.71\n",
      "CPU times: user 2.23 s, sys: 462 µs, total: 2.23 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(LogisticRegression(random_state=12345, class_weight = 'balanced'), X_train_tf, y_train, X_valid_tf, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression on data balanced using upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.72\n",
      "CPU times: user 3.75 s, sys: 12.7 ms, total: 3.76 s\n",
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(LogisticRegression(random_state=12345), X_train_up, y_train_up, X_valid_tf, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.68\n",
      "CPU times: user 58.2 s, sys: 19 ms, total: 58.3 s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(RandomForestClassifier(), X_train_up, y_train_up, X_valid_tf, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.73\n",
      "CPU times: user 6min 37s, sys: 1.53 s, total: 6min 39s\n",
      "Wall time: 6min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(LGBMClassifier(), X_train_up, y_train_up, X_valid_tf, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GradientBoostingClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.68\n",
      "CPU times: user 3min 14s, sys: 25.7 ms, total: 3min 14s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(GradientBoostingClassifier(), X_train_up, y_train_up, X_valid_tf, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>time, s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression_b</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.64</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.73</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.68</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  RMSE  time, s\n",
       "0        LogisticRegression_b  0.75       18\n",
       "1          LogisticRegression  0.76       22\n",
       "2      RandomForestClassifier  0.64      150\n",
       "3              LGBMClassifier  0.73      230\n",
       "4  GradientBoostingClassifier  0.68      240"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model' : ['LogisticRegression_b', 'LogisticRegression', 'RandomForestClassifier', 'LGBMClassifier', 'GradientBoostingClassifier'],\n",
    "    'RMSE' :pd.Series([0.75, 0.76, 0.64, 0.73, 0.68]),\n",
    "     'time, s': pd.Series([18, 22, 150, 230, 240])\n",
    "    }\n",
    "df1 = pd.DataFrame(d)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking on the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.76\n",
      "CPU times: user 6.08 s, sys: 27.9 ms, total: 6.11 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(LogisticRegression(random_state=12345), X_train_up, y_train_up, X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result and working speed was shown by the Logistic Regression model, trained on balanced data:\n",
    "\n",
    "- f1 = 0.76\n",
    "- Wall time: 6.12 s  \n",
    "\n",
    "The result was confirmed on the test sample.  \n",
    "  \n",
    "The LGBMClassifier model looks promising, theoretically, you can select hyperparameters to improve its result, but the working speed does not allow this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*The speed of models' work changes significantly in different runs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of project implementation, the most promising method of processing and classifying texts was the BERT neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT (Bidirectional Encoder Representations from Transformers) is a neural network for creating a language model. It was developed by Google to improve the relevance of search results. This algorithm understands the context of queries, not just analyzes phrases. For machine learning, it is valuable because it helps to build vector representations. Moreover, in text analysis, a model that is already pretrained on a large corpus is used. These pretrained versions of BERT are suitable for working with texts in 104 languages of the world, including Russian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is almost impossible to train it at home, so the selection of a model pretrained on a relevant dictionary plays a big role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we use the DistilBERT model.  \n",
    "  \n",
    "DistilBERT is a downsized version of BERT, developed and made publicly available by a group of HuggingFace developers. It is faster and lighter than its elder brother, but still quite comparable in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that the model is already pretrained, its use takes a lot of time, so in the project we will use it on a sample of 200 comments.\n",
    "\n",
    "In the test version, a sample of 2000 comments was also used, but in this case, the work of the model took 30 minutes.\n",
    "I didn't leave it in the final version of the project, I'll briefly describe its result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df_comments[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained DistilBERT model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a804f509d2459fb5fa3b4e5a670e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d95fd3634409c92634057782a9303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98148f35966486995e3a84aa936087d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the correct operation of the model, we need to limit the length of comments to 512 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1['text'] = batch_1['text'].str[:512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = batch_1['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset now represents a list of lists. Before DistilBERT processes it at the input, we need to bring vectors to one size by adding the identifier 0 (padding) to shorter vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explain to the model that zeros don't carry significant information. This is necessary for the component of the model called \"attention\".  \n",
    "\n",
    "We will discard these tokens and \"create a mask\" for really important tokens, i.e. we will indicate zero and non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 230)\n"
     ]
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create embeddings for user comments, limiting the batch size to 50 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd992c78e9f3400ea499c69c36def0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect all embeddings into a feature matrix by calling the concatenate function, highlight the target feature, and divide the data into training and testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = batch_1['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.67\n",
      "CPU times: user 69.1 ms, sys: 36.6 ms, total: 106 ms\n",
      "Wall time: 59.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_models(LogisticRegression(random_state=12345, class_weight = 'balanced'), features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a sample of 200 comments, BERT in conjunction with logistic regression showed an f1 score of 0.67 and a running time of about 4 minutes.\n",
    "The result on a sample of 2000 comments was 0.72, with a running time of 35 minutes.  \n",
    "  \n",
    "We can suggest that on the full sample, the result will be equal or better than that of our logistic regression model trained on vectorized data using the tf-idf method, but in this case, BERT will take a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we trained a model to classify comments as positive or negative.\n",
    "The best result in terms of quality and speed was shown by the logistic regression model, trained on vectorized and balanced data.\n",
    "\n",
    "- f1 = 0.76\n",
    "- Wall time: 6.6 s  \n",
    "\n",
    "Other models could theoretically show a better result, but their running time is significantly longer and bringing them to a suitable state would take a very large amount of time given the available computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
